{
  "improve_classification_only": {
    "type": "change_parameters",
    "is_generation": false,
    "task": null,
    "addon_task": null,
    "input_list": [ {"para": "nn_code","value": "nn_code"},
                    {"para": "accuracy","value": "accuracy"},
                    {"para": "epoch","value": "epoch"},
                    {"para": "dataset","value": "dataset"},
                    {"para": "task","value": "task"},
                    {"para": "metric","value": "metric"},
                    {"para": "metric_code","value": "metric_code"},
                    {"para": "transform_code","value": "transform_code"},
                    {"para": "prm","value": "prm"},
                    {"para": "addon_accuracy","value": "accuracy_2"},
                    {"para": "addon_epoch","value": "epoch_2"},
                    {"para": "addon_nn_code","value": "nn_code_2"},
                    {"para": "addon_transform_code","value": "transform_code_2"},
                    {"para": "addon_prm","value": "prm_2"}
    ],
    "no_repeat": ["nn"],
    "keep_same": ["epoch", "metric", "dataset", "task"],
    "nn_prefixes": [],
    "num_joint_nns": 2,
    "improve": true,
    "prompt": [
      "## Role",
      "You are a visionary deep learning architect renowned for designing breakthrough neural networks by drawing inspiration from diverse scientific domains.",
      "## Task",
      "Create an innovative vision model that maximizes '{metric}' on '{dataset}' for '{task}' at epoch {epoch}. Reference model achieved {accuracy} — use it as inspiration, NOT a constraint.",
      "",
      "CROSS-DOMAIN INNOVATION PRINCIPLES - Draw from: (1) Biological Vision: foveated attention, hierarchical cortical processing, lateral inhibition, V4/IT recurrent feedback; (2) Signal Processing: wavelets, frequency-domain convolutions, sparse coding; (3) Graph Theory: message passing, spectral convolutions; (4) Physics: diffusion, energy-based models, symmetry/equivariance; (5) Neuroscience: predictive coding, Hebbian dynamics.",
      "",
      "YOU MUST INNOVATE IN ALL THREE AREAS:",
      "1. HYPERPARAMETERS <hp>...</hp>: Experiment boldly — try unconventional batch sizes (very small for gradient noise, or large with warmup), novel learning rate schedules (cosine annealing, cyclic, warmup restarts), weight decay variations, gradient clipping, label smoothing, mixup/cutmix alpha values. Keys: \"batch\", \"transform\", plus all 'supported_hyperparameters' keys. Avoid \"hp*\" keys.",
      "2. TRANSFORM CODE <tr>...</tr>: Go beyond standard augmentations — implement RandAugment, AutoAugment, CutOut, GridMask, random erasing, Fourier-domain augmentation, style transfer augmentation, or bio-inspired transformations (e.g., simulating retinal preprocessing). Use torchvision or custom implementations.",
      "3. NEURAL NETWORK <nn>...</nn>: Make FUNDAMENTAL architectural changes — mixture-of-experts, dynamic routing, memory-augmented modules, hypernetworks, reversible layers, neural ODEs, capsule networks, attention mechanisms (SE, CBAM, ECA), multi-scale feature fusion (FPN, BiFPN), inverted residuals, depthwise separable convs, or hybrid CNN+Transformer+MLP-Mixer designs.",
      "",
      "Reference configuration: ",
      "<hp>{prm}</hp>",
      "<tr>{transform_code}</tr>",
      "<metric>{metric_code}</metric>",
      "<nn>{nn_code}</nn>",
      "",
      "## Limitations",
      "",
      "1. You have a limited number of tokens(8192) to use. You must use them wisely. The GPU memory is limited, so use small batch size.",
      "2. Prefer to use .reshape() instead of .view() for robustness.",
      "3. Ensure code follows LEMUR NN Dataset conventions.",
      "    - Class Structure: Main class must be named Net residing in a file named after the model architecture.",
      "    - Initialization: __init__ signature must be exactly def __init__(self, in_shape, out_shape, prm, device):.",
      "    - Dynamic Configuration: Extract input channels/dimensions from in_shape (e.g., (B, C, H, W)) and number of classes from out_shape. Do not hardcode these.",
      "    - Hyperparameters: Access hyperparameters exclusively via the prm dictionary (e.g., prm['lr']).",
      "    - Metadata: Include a top-level function def supported_hyperparameters(): returning a set of all hyperparameter keys used by the model.",
      "    - Methods: Implement train_setup(self, prm) to initialize the optimizer/criterion and learn(self, train_data) to execute the training loop.",
      "4. Output ONLY three XML tags in order: <hp>...</hp>, <tr>...</tr>, <nn>...</nn>. No JSON wrapping, no markdown, no explanations."
    ],
    "output": [
      "<hp>{addon_prm}</hp>",
      "<tr>{addon_transform_code}</tr>",
      "<nn>{addon_nn_code}</nn>"
    ]
  }
}